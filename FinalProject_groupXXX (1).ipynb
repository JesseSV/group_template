{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesions and Clustering Models\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Tom Hocquet\n",
    "- Jesse Sanchez Villegas\n",
    "- Kian Ekhlassi\n",
    "- Jiawei Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "<!-- This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables -->\n",
    "\n",
    "Our goal is to be able to predict what type of skin lesion the patient has. The data we used consist of images that have Melanoma ,Melanocytic nevus,Basal cell carcinoma,Actinic keratosis,Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis), Dermatofibroma , Vascular lesion, Squamous cell carcinoma, or none of the above. We will be conducting photo segmentation to highlight and cluster similar features.Specifically our data consist of images which we will be converting into vectors, then use several clustering models like Kmeans to group the images with respect to each other to see if it can find a pattern within the vectors. From here we will have our model predict what lesion the patient has. Performance will be measured through its accuracy score, recall and F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "<!-- Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated.  -->\n",
    "\n",
    "Skin lesions are a critical visible symptom of a potentially harmful disease but study shows that a significant amount of patients are unaware of carrying these diseases[1]. This leads to the conclusion that a vast majority of the population are uneducated despite the life altering consequences that can arise if not treated soon. This undiagnosed issue is explained by the increase in cost it takes to fully diagnose and treat skin lesions which discourages the general public in pursuing. Along with this, many diagnosed patients have spoken about their experiences and worry that they are oftentimes inspected by untrained physicians [2]. \n",
    "Overall it is apparent that the uneducated populace over a fairly common disease especially to elderly people, needs to have some changes. Our research is intended to create a model so that people can send pictures and ideally get an accurate prediction of what type of skin lesion they may have. Note this is not to replace the role of a trained professional, since the issue of misdiagnosing a possibly life threatening disease is not our goal. Instead our goal is to help the general public get a name of the possible disease they may have to be able to consult to the trained professional to get treatment in a timely manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "<!-- Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once). -->\n",
    "\n",
    "The problem that we are solving is can we create a model to accurately predict what type of skin lesion a patient has (Melanoma, Melanocytic nevus, Basal cell carcinoma, Actinic keratosis, Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis), Dermatofibroma, Vascular lesion, or Squamous cell carcinoma) based on an image of the patient’s affected skin. We will be conducting image segmentation to classify skin lesions from image through some kind of clustering algorithm such as k-means, DBSCAN, Hierarchical clustering, and Gaussian Mixed Models. The problem is quantifiable because visual features such as color, shape and size of the skin lesion can be quantified. Specifically, pixel intensities and values that represent the color scale can be used to quantify image of skin lesion. Similarly, we can measure and evaluate the performance of our constructed classification model through metrics like accuracy, recall and F1 score. Moreover, this process of classification is vastly replicable because skin lesions are common symptoms among many patients and diagnosis of type of skin lesions occur frequently in clinical practices. By creating this classification model, we want to provide the general public with an easily accessible method of skin lesion diagnosis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "<!-- Detail how/where you obtained the data and cleaned it (if necessary)\n",
    "\n",
    "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n",
    " -->\n",
    " \n",
    "Link to the dataset: https://www.kaggle.com/datasets/andrewmvd/isic-2019?resource=download\n",
    "- Dataset Name: ISIC_2019_Training_Metadata\n",
    "- \\# of variables: 5; \\# of observations: 25331\n",
    "- Observation consists of: image (filename), age_approx(approximated age), anatom_site_general(anatomical site of image), lesion_Id (id of lesion), sex(sex of the patient)\n",
    "- The most critical variable is the image, which is represented by its corresponding filename and stored in JPEG. The anatom_site_general is also a critical variable that stores the label of the anatomical site of the image. Some of the labels include anterior torso, lower extremity, higher extremity and palms/soles.\n",
    "- For the images of the patients affected skin, we plan to encode these JPEG images and conduct pixel normalization in binary format during our preprocessing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "<!-- In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared.  -->\n",
    "\n",
    "Our goal is to properly classify skin lesions from images. To solve this problem, we will use a mix of techniques. First we will do data preprocessing in order to make sure our data is in a form that we can use. Then we will use an unsupervised clustering algorithm to see if we can cluster different images easily. We will likely try k-means, DBSCAN, Hierarchical clustering, and Gaussian Mixed Models. We might need to do dimensionality reduction (PCA, maybe convolution) in order for these methods to work due to the curse of dimensionality. If we find that a specific clustering algorithm works particularly well, we will likely use it. We will also need to use a CNN to finalize our predictions with the help of the insights gained from clustering. \n",
    "To test our solution we will use a cross-validation technique with a testing sample separated at the beginning on which we can test on at the very end. We will use the evaluation metrics below to measure our “success.” We will also use a benchmark model using KMeans (as it is the simplest model) for our solution to be compared against. \n",
    "Libraries that we will use will likely include but is not limited to:\n",
    "Pandas, numpy, sklearn.cluster.(KMeans, DBSCAN …), sklearn.metrics, pytorch, tensorflow, matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Since we are dealing with a classification problem, doing a metric that measures our successes and failures accurately will be best. Maximizing the True Positive Rate will be our goal (recall, TP/P). We will also likely use the Positive Predictive Value (precision, TP/PP) and the F-score (2 TP /( 2 TP + FP + FN)) as it can balance if some of the size of classes is significantly different from the other. These three metrics will make sure to guide our solution to the right direction. Using these three metrics we should be able to evaluate our model accurately and we will also be able to use these tests for our validation and test set which will tell us if our model is generalizing well or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the commands\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "\n",
    "# to get rid of warnings during models\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*threadpoolctl.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('grayscale_img.csv.zip','r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are defining functions that we will be using on the data in order to reduce the size of the orinigal images so that we can reduce computational power needed. Since we are reducing the size we want to make up for it my calculating the average of the images and recreating the images using the averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a directory\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        #images are in jpg format\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "# Function to calculate average pixel values\n",
    "def calculate_average_pixels(images):\n",
    "    return np.mean(images, axis=(1, 2))\n",
    "\n",
    "# Function to resize images using average pixel values\n",
    "def resize_images(images, new_size=(30, 30)):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        #built in the average pixel function within the resizing\n",
    "        resized_image = np.full((new_size[0], new_size[1], 3), calculate_average_pixels([image]))\n",
    "        resized_images.append(resized_image)\n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from dataset\n",
    "dataset_directory = os.path.join('archive','ISIC_2019_Training_Input','ISIC_2019_Training_Input')\n",
    "images = load_images(dataset_directory)\n",
    "\n",
    "# Calculate average pixel values\n",
    "average_pixels = calculate_average_pixels(images)\n",
    "\n",
    "# Resize images using average pixel values\n",
    "resized_images = resize_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to show us the comparison of the first 3 images between resized(avg) image to the original. Also will be a good indication for us to see if the avg pixel is a good basis to base the kmeans and make conclusions on or if its too drastically different to acknowledge that and consider it for our final conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the original and resized image\n",
    "for i in range(3):\n",
    "    cv2.imshow('Original', images[i])\n",
    "    cv2.imshow('Resized', resized_images[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale = pd.read_csv(os.path.join('grayscale_img.csv', 'grayscale_img.csv'), index_col = 0)\n",
    "\n",
    "grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X_gray = grayscale.drop(columns = ['label'])\n",
    "y_gray = grayscale['label']\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit_transform(X_gray, y_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = pd.read_csv(os.path.join('resized_images_color.csv', 'resized_images_color.csv'))\n",
    "\n",
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X_color = color.drop(columns = ['label'])\n",
    "y_color = color['label']\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit_transform(X_color, y_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be using the data to conduct kmeans. Note the data set we will be testing on is a grayscaled, reduced sized (originally 512x512 into 30x30), and grayscaled for computational reasons. We want to point this out as it will affect results, given we are reducing and getting rid of possible features that may be important for better predictions. We used the average of pixels before reducing the size of the images to make up for the reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv that has all the changes applied already\n",
    "df = pd.read_csv(\"grayscale_img.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_clust(df, n_clusters=8):\n",
    "    # Convert DataFrame to numpy array\n",
    "    data = df.values\n",
    "    \n",
    "    # Flatten the data\n",
    "    flattened_data = data.reshape(data.shape[0], -1)\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(flattened_data)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=2)\n",
    "    data_reduced = pca.fit_transform(data_scaled)\n",
    "    \n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(data_reduced)\n",
    "    \n",
    "    # Visualize the clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cluster in range(n_clusters):\n",
    "        plt.scatter(data_reduced[cluster_labels == cluster, 0], \n",
    "                    data_reduced[cluster_labels == cluster, 1], \n",
    "                    label=f'Cluster {cluster + 1}')\n",
    "    plt.title('Clusters Visualization')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Filter numeric columns bc some vectors contain string\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "# Call vis_clust only num values, because cant run with strings\n",
    "vis_clust(numeric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "\n",
    "Now that we have the images preprocessed, we know there should be 8 different clusters since the images contain 8 different skin conditions, but we want to see how it will cluster them using k means. Also since we are doing a unsupervised portion we will be using a elbow method to decide the number of clusers, and compare to the actual amount we know is true.\n",
    "\n",
    "The kmeans at 8 clusters does a good job at clustering. Our only concern would be the top right section between cluster 4 and 5 but that is a given due to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(df, max_clusters=10):\n",
    "    distortions = []\n",
    "    for n_clusters in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        kmeans.fit(df)\n",
    "        # Sum of squared distances to closest centroid\n",
    "        distortions.append(kmeans.inertia_)  \n",
    "\n",
    "    # Plotting the elbow method\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, max_clusters + 1), distortions, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Select only numeric columns from the DataFrame\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "numeric_data = df[numeric_columns]\n",
    "\n",
    "# Prepare data\n",
    "flattened_data = np.array([image.flatten() for image in numeric_data.values])\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(flattened_data)\n",
    "\n",
    "# Run elbow method\n",
    "elbow_method(data_scaled, max_clusters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that based off the elbow graph between 2-4 is ideal for the number of clusters for our kmeans. It makes sense that it would be less than 8 because that would be overfitting, but another reason for this can be that skin lesions may minor differences, that the kmeans overlooked. We will compare how a cluster of 3 looks with respect to cluster of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# Plot with 8 clusters\n",
    "axs[0].set_title('8 clusters')\n",
    "vis_clust(numeric_df, n_clusters=8)\n",
    "\n",
    "# Plot with 3 clusters\n",
    "axs[1].set_title('3 clusters')\n",
    "vis_clust(numeric_df, n_clusters=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our df's last column contains the truths of each image, we will now be using this column to see how accurate the kmeans is with respect to what we know is true. We will be testing this for clusters=3, and 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out all the unique strings in the last column\n",
    "unique_strings = df.iloc[:, -1].unique()\n",
    "print(unique_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#Extract truths from df last column\n",
    "true_labels = df.iloc[:, -1]\n",
    "# kmeans 3 clusters\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_3.fit(data_scaled)\n",
    "labels_3 = kmeans_3.labels_\n",
    "\n",
    "#kmeans 8 clusters\n",
    "kmeans_8 = KMeans(n_clusters=8, random_state=42)\n",
    "kmeans_8.fit(data_scaled)\n",
    "labels_8 = kmeans_8.labels_\n",
    "\n",
    "# Mapping clusters to true labels\n",
    "cluster_mapping = {\n",
    "    0: 'NV',\n",
    "    1: 'MEL',\n",
    "    2: 'BKL',\n",
    "    3: 'DF',\n",
    "    4: 'SCC',\n",
    "    5: 'BCC',\n",
    "    6: 'VASC',\n",
    "    7: 'AK'\n",
    "}\n",
    "\n",
    "# Map cluster labels to true labels for 3 clusters\n",
    "predicted_labels_3 = [cluster_mapping[label] for label in labels_3]\n",
    "\n",
    "# Map cluster labels to true labels for 8 clusters\n",
    "predicted_labels_8 = [cluster_mapping[label] for label in labels_8]\n",
    "\n",
    "# Compare the accuracy of the clustering results\n",
    "accuracy_3 = accuracy_score(true_labels, predicted_labels_3)\n",
    "accuracy_8 = accuracy_score(true_labels, predicted_labels_8)\n",
    "# Print the first few predicted labels for each clustering\n",
    "print(\"\\nPredicted Labels for 3 clusters:\")\n",
    "print(predicted_labels_3[:10])  # Print the first 10 predicted labels for 3 clusters\n",
    "print(\"\\nPredicted Labels for 8 clusters:\")\n",
    "print(predicted_labels_8[:10])  # Print the first 10 predicted labels for 8 clusters\n",
    "print(\"Accuracy with 3 clusters:\", accuracy_3)\n",
    "print(\"Accuracy with 8 clusters:\", accuracy_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to our low accuracy score in our image predicting models. We looked to the metadata of the images in an attempt to create a predictive model using those statistics of the patients and see if that is better at prediciting the skin lesion. \n",
    "\n",
    "Things to know from the following data it consists of 5 columns (image, age_approx, site, lesion id, sex). We needed to clean the data a bit specifically remove any rows without a lesion id. We then got rid of portion of the string in the lesion id, because the data included the lesion id with respect to the image. The reason for this is to be able to use this column as our ground truths for validation. Lastly we convert the sex column from string to numerical values in our case female=0, and male=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata from the CSV file\n",
    "metadata_df = pd.read_csv(\"ISIC_2019_Training_Metadata.csv\")\n",
    "\n",
    "# Drop rows where 'lesion_id' is blank or missing\n",
    "metadata_df.dropna(subset=['lesion_id'], inplace=True)\n",
    "\n",
    "# Remove characters after the underscore in 'lesion_id' column\n",
    "metadata_df['lesion_id'] = metadata_df['lesion_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Convert strings in the 'sex' column to numerical values\n",
    "metadata_df['sex'] = metadata_df['sex'].map({'female': 0, 'male': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "\n",
    "We will now be creating a hierarchical clustering dendogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "metadata_df['anatom_site_general'] = label_encoder.fit_transform(metadata_df['anatom_site_general'])\n",
    "\n",
    "# Select features for clustering\n",
    "features = metadata_df[['age_approx', 'anatom_site_general','sex']]\n",
    "# Impute NaN values with mean\n",
    "features = features.fillna(features.mean())\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(features, method='ward')\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z, truncate_mode='lastp', p=30, leaf_rotation=90., leaf_font_size=8.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adjusted the x axis, to show the range of sample index's otherwise it would not be legible given the number of samples we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "#Remove missing or blank values from metadata\n",
    "metadata_df = metadata_df.dropna(subset=['lesion_id'])\n",
    "\n",
    "#Ground Truth for validation\n",
    "ground_truth_labels = metadata_df['lesion_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "#Define a range of threshold distances\n",
    "thresholds = range(10, 500, 5)\n",
    "\n",
    "best_ari = -1\n",
    "best_t = None\n",
    "\n",
    "for t in thresholds:\n",
    "    # Obtain cluster labels\n",
    "    cluster_labels = fcluster(Z, t, criterion='distance')\n",
    "    \n",
    "    # Calculate ARI\n",
    "    ari = adjusted_rand_score(ground_truth_labels, cluster_labels)\n",
    "    \n",
    "    # Update best ARI and threshold if ARI improves\n",
    "    if ari > best_ari:\n",
    "        best_ari = ari\n",
    "        best_t = t\n",
    "\n",
    "print(\"Best threshold distance (t):\", best_t)\n",
    "print(\"Best Adjusted Rand Index (ARI):\", best_ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The for loop was used to find the best t value to get the highest ari. Unfortunately we still have a low score of  less than .1 which means our clustering did a very poor job at correctly prediciting with respect to the ground truths\n",
    "\n",
    "The following we will be doing a second Hierarchical Clustering but this time we will imnplement weights to the features to see if this will improve ARI score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have metadata features stored in 'X' and lesion types stored in 'y'\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_scaled, ground_truth_labels)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Normalize feature importances to create weights\n",
    "weights = feature_importances / feature_importances.sum()\n",
    "\n",
    "# Print feature importance weights\n",
    "print(\"Feature Importance Weights:\")\n",
    "for feature, weight in zip(metadata_df.columns, weights):\n",
    "    print(f\"{feature}: {weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Normalize metadata features using weights\n",
    "weighted_features = X_scaled * weights\n",
    "\n",
    "# Compute the weighted Euclidean distance matrix\n",
    "weighted_distance_matrix = pdist(weighted_features)\n",
    "\n",
    "# Perform hierarchical clustering with weighted distance matrix\n",
    "Z = linkage(weighted_distance_matrix, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Hierarchical Clustering Dendrogram with Weights')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z, truncate_mode='lastp', p=30, leaf_rotation=90., leaf_font_size=8.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Remove missing or blank values from metadata\n",
    "metadata_df = metadata_df.dropna(subset=['lesion_id'])\n",
    "\n",
    "# Ground Truth for validation\n",
    "ground_truth_labels = metadata_df['lesion_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Define a range of threshold distances\n",
    "thresholds = range(10, 500, 5)\n",
    "\n",
    "best_ari = -1\n",
    "best_t = None\n",
    "\n",
    "for t in thresholds:\n",
    "    # Obtain cluster labels with weighted hierarchical clustering\n",
    "    cluster_labels = fcluster(Z, t, criterion='distance')\n",
    "    \n",
    "    # Calculate ARI\n",
    "    ari = adjusted_rand_score(ground_truth_labels, cluster_labels)\n",
    "    \n",
    "    # Update best ARI and threshold if ARI improves\n",
    "    if ari > best_ari:\n",
    "        best_ari = ari\n",
    "        best_t = t\n",
    "\n",
    "print(\"Best threshold distance (t):\", best_t)\n",
    "print(\"Best Adjusted Rand Index (ARI):\", best_ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our ARI has increased significantly when we incorporated weights before it was roughly 0.02 and now the ARI is roughly 0.16. Meaning our model improved in predicting the ground truth, but it is still low when considering the ARI score where ARI=1 perfect prediction. With this said since it is >0 meaning it performs better than random preiction.\n",
    "\n",
    "### Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_clust_gmm(data, n_clusters=9):\n",
    "    flattened_data = np.array([image.flatten() for image in data])\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(flattened_data)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    data_reduced = pca.fit_transform(data_scaled)\n",
    "\n",
    "    #Gaussian Mixture Model\n",
    "    gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    gmm.fit(data_reduced)\n",
    "    cluster_labels = gmm.predict(data_reduced)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        plt.scatter(data_reduced[cluster_labels == cluster, 0], \n",
    "                    data_reduced[cluster_labels == cluster, 1], \n",
    "                    label=f'Cluster {cluster + 1}')\n",
    "    plt.title('GMM Clusters Visualization')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "vis_clust_gmm(resized_images, n_clusters=9) \n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def evaluate_gmm_silhouette(data, n_clusters=9):\n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(data_reduced, cluster_labels)\n",
    "    print(f'Silhouette Score for {n_clusters} clusters: {silhouette_avg:.3f}')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        plt.scatter(data_reduced[cluster_labels == cluster, 0], \n",
    "                    data_reduced[cluster_labels == cluster, 1], \n",
    "                    label=f'Cluster {cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/demo/Desktop/COGS118B_WI_24/Project/archive/ISIC_2019_Training_GroundTruth.csv\", header = 0)\n",
    "lesion_type_dict = {\n",
    "    'NV': 'Melanocytic nevi',\n",
    "    'MEL': 'Melanoma',\n",
    "    'BKL': 'Benign keratosis ',\n",
    "    'BCC': 'Basal cell carcinoma',\n",
    "    'AK': 'Actinic keratoses',\n",
    "    'VASC': 'Vascular lesions',\n",
    "    'DF': 'Dermatofibroma',\n",
    "    'SCC' : 'Squamous cell carcinoma'\n",
    "}\n",
    "data['truth'] = data.drop(columns='image').idxmax(axis=1)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    dir = Path(path)\n",
    "    filepaths = list(dir.glob(r'**/*.jpg'))\n",
    "    labels = data['truth']\n",
    "    filepaths = pd.Series(filepaths, name='FilePaths').astype(str)\n",
    "    labels = pd.Series(labels, name='Labels').astype(str)\n",
    "    df = pd.merge(filepaths, labels, right_index=True, left_index=True)\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "df = load_data('/Users/demo/Desktop/COGS118B_WI_24/Project/archive/ISIC_2019_Training_Input/ISIC_2019_Training_Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count = df['Labels'].value_counts(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(labels_count.index, labels_count.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Labels'] = df['Labels'].apply(lambda x: x if x == 'NV' else 'OTH')\n",
    "df_binary = df['Labels']\n",
    "binary = np.array([-1 if x == 'OTH' else 1 for x in df_binary])\n",
    "binary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data is heavily biased towards NV, and has low numbers of other diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('archive/ISIC_2019_Training_GroundTruth.csv')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesWithLabels = pd.DataFrame()\n",
    "filesWithLabels['file'] = files['image']+'.jpg'\n",
    "filesWithLabels['label'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesWithLabels['label'] = data['truth']\n",
    "filesWithLabels['file'] = 'archive/ISIC_2019_Training_Input/ISIC_2019_Training_Input/'+filesWithLabels['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(filesWithLabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 1\n",
    "def get_model():   \n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(128, 128, 3)),\n",
    "        Conv2D(16, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\", padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,  \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "def plot_history(history, title):\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_models(model,name):\n",
    "    dest_folder = '/kaggle/working/'\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    with open(dest_folder  + name +\".tflite\", 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "def create_model(table, name, epoch):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=table,\n",
    "        directory=None,\n",
    "        x_col='file',\n",
    "        y_col='label',\n",
    "        subset=\"training\",\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"binary\",\n",
    "        target_size=(128, 128))\n",
    "    validation_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=table,\n",
    "        directory=None,\n",
    "        x_col='file',\n",
    "        y_col='label',\n",
    "        subset=\"validation\",\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"binary\",\n",
    "        target_size=(128, 128))\n",
    "    # Create a function that yields samples\n",
    "    model = get_model()\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(train_generator, epochs=epoch, validation_data=validation_generator, callbacks=[early_stop])\n",
    "    return history, model     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVTable = pd.concat([X_train.loc[X_train['label'] != 'NV'].sample(n=8000), X_train.loc[X_train['label'] == 'NV']])\n",
    "NVTable['label'] = NVTable['label'].apply(lambda x: 'OTH' if x != 'NV' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'MEL'].shape[0]\n",
    "MELTable = pd.concat([X_train.loc[X_train['label'] != 'MEL'].sample(n=n), X_train.loc[X_train['label'] == 'MEL']])\n",
    "MELTable['label'] = MELTable['label'].apply(lambda x: 'OTH' if x != 'MEL' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'BKL'].shape[0]\n",
    "BKLTable = pd.concat([X_train.loc[X_train['label'] != 'BKL'].sample(n=n), X_train.loc[X_train['label'] == 'BKL']])\n",
    "BKLTable['label'] = BKLTable['label'].apply(lambda x: 'OTH' if x != 'BKL' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'DF'].shape[0]\n",
    "DFTable = pd.concat([X_train.loc[X_train['label'] != 'DF'].sample(n=n), X_train.loc[X_train['label'] == 'DF']])\n",
    "DFTable['label'] = DFTable['label'].apply(lambda x: 'OTH' if x != 'DF' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'SCC'].shape[0]\n",
    "SCCTable = pd.concat([X_train.loc[X_train['label'] != 'SCC'].sample(n=n), X_train.loc[X_train['label'] == 'SCC']])\n",
    "SCCTable['label'] = SCCTable['label'].apply(lambda x: 'OTH' if x != 'SCC' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'BCC'].shape[0]\n",
    "BCCTable = pd.concat([X_train.loc[X_train['label'] != 'BCC'].sample(n=n), X_train.loc[X_train['label'] == 'BCC']])\n",
    "BCCTable['label'] = BCCTable['label'].apply(lambda x: 'OTH' if x != 'BCC' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'VASC'].shape[0]\n",
    "VASCTable = pd.concat([X_train.loc[filesWithLabels['label'] != 'VASC'].sample(n=n), X_train.loc[X_train['label'] == 'VASC']])\n",
    "VASCTable['label'] = VASCTable['label'].apply(lambda x: 'OTH' if x != 'VASC' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'AK'].shape[0]\n",
    "AKTable = pd.concat([X_train.loc[X_train['label'] != 'AK'].sample(n=n), X_train.loc[X_train['label'] == 'AK']])\n",
    "AKTable['label'] = AKTable['label'].apply(lambda x: 'OTH' if x != 'AK' else x)\n",
    "\n",
    "tables = {\n",
    "    \"AK\": AKTable,\n",
    "    \"NV\": NVTable,\n",
    "    \"MEL\": MELTable,\n",
    "    \"BKL\": BKLTable,\n",
    "    \"DF\": DFTable,\n",
    "    \"SCC\": SCCTable,\n",
    "    \"BCC\": BCCTable,\n",
    "    \"VASC\": VASCTable,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tables.keys():\n",
    "    hist_1, mdl_1 = create_model(tables[i], str(i) + \" model, validation\", 7)\n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=tables[i],  # Your test DataFrame\n",
    "        directory=None,  # Adjust if your file paths are relative\n",
    "        x_col='file',  # Column in X_test that contains the file paths\n",
    "        y_col='label',  # Column in X_test that contains the labels\n",
    "        batch_size=64,  # Can adjust based on your preference\n",
    "        seed=42,\n",
    "        shuffle=False,  # Keep it False to maintain order, important for evaluation\n",
    "        class_mode=\"binary\",  # or \"categorical\" based on your model\n",
    "        target_size=(128, 128)\n",
    "        )\n",
    "    eval_result = mdl_1.evaluate(test_generator)\n",
    "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
    "    plot_history(hist_1, str(i) + \" model, validation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Computational power was a big limitation for us as ideally we would perform our models on the original 512x512 pixels. Some problems that were pointed out in Kaggle were that some of the data had repeated samples. This affects the score. Another issue was that our images had a lot of noise, speccifcally the skin surrounding the skin lesion. This could explain our low accuracy as not everyone has the same skin, and the images were not zoomed in properly. Finally our images were proccesed to being smaller and grayscaled which we can predict also limited our clustering models.   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "In terms of ethical concerns the main issue is where the images are sourced from, and whether or not the people in the photos have given their consent for researchers to study them. In our case photos do not contain any faces, they are high resolution photos of the skin disease site only. It seems some sort of microscope was used to take these pictures. The data was obtained from a hospital in Barcelona, where the patient's consent was given. We sourced the dataset from Kaggle which is a reliable source for ethical data. Another ethical concern is what this data will be used for. In our case the model we create will only benefit humanity, because people can detect skin melanoma or other cancerous diseases in early stages and seek medical care as soon as possible.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
