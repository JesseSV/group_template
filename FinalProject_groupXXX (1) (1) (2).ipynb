{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesions and Clustering Models\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Tom Hocquet\n",
    "- Jesse Sanchez Villegas\n",
    "- Kian Ekhlassi\n",
    "- Jiawei Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "<!-- This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables -->\n",
    "\n",
    "Our goal is to be able to predict what type of skin lesion the patient has. The data we used consist of images that have Melanoma ,Melanocytic nevus,Basal cell carcinoma,Actinic keratosis,Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis), Dermatofibroma , Vascular lesion, Squamous cell carcinoma, or none of the above. We will be conducting photo segmentation to highlight and cluster similar features.Specifically our data consist of images which we will be converting into vectors, then use several clustering models like Kmeans to group the images with respect to each other to see if it can find a pattern within the vectors. From here we will have our model predict what lesion the patient has. Performance will be measured through its accuracy score, recall and F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "<!-- Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated.  -->\n",
    "\n",
    "Skin lesions are a critical visible symptom of a potentially harmful disease but study shows that a significant amount of patients are unaware of carrying these diseases[1]. This leads to the conclusion that a vast majority of the population are uneducated despite the life altering consequences that can arise if not treated soon. This undiagnosed issue is explained by the increase in cost it takes to fully diagnose and treat skin lesions which discourages the general public in pursuing. Along with this, many diagnosed patients have spoken about their experiences and worry that they are oftentimes inspected by untrained physicians [2]. \n",
    "Overall it is apparent that the uneducated populace over a fairly common disease especially to elderly people, needs to have some changes. Our research is intended to create a model so that people can send pictures and ideally get an accurate prediction of what type of skin lesion they may have. Note this is not to replace the role of a trained professional, since the issue of misdiagnosing a possibly life threatening disease is not our goal. Instead our goal is to help the general public get a name of the possible disease they may have to be able to consult to the trained professional to get treatment in a timely manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "<!--  -->\n",
    "\n",
    "The problem that we are solving is can we create a model to accurately predict what type of skin lesion a patient has (Melanoma, Melanocytic nevus, Basal cell carcinoma, Actinic keratosis, Benign keratosis (solar lentigo / seborrheic keratosis / lichen planus-like keratosis), Dermatofibroma, Vascular lesion, or Squamous cell carcinoma) based on an image of the patient’s affected skin. We will be conducting image segmentation to classify skin lesions from image through some kind of clustering algorithm such as k-means, DBSCAN, Hierarchical clustering, and Gaussian Mixed Models. The problem is quantifiable because visual features such as color, shape and size of the skin lesion can be quantified. Specifically, pixel intensities and values that represent the color scale can be used to quantify image of skin lesion. Similarly, we can measure and evaluate the performance of our constructed classification model through metrics like accuracy, recall and F1 score. Moreover, this process of classification is vastly replicable because skin lesions are common symptoms among many patients and diagnosis of type of skin lesions occur frequently in clinical practices. By creating this classification model, we want to provide the general public with an easily accessible method of skin lesion diagnosis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "<!-- Detail how/where you obtained the data and cleaned it (if necessary)\n",
    "\n",
    "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n",
    " -->\n",
    " \n",
    "Link to the dataset: https://www.kaggle.com/datasets/andrewmvd/isic-2019?resource=download\n",
    "- Dataset Name: ISIC_2019_Training_Metadata\n",
    "- \\# of variables: 5; \\# of observations: 25331\n",
    "- Observation consists of: image (filename), age_approx(approximated age), anatom_site_general(anatomical site of image), lesion_Id (id of lesion), sex(sex of the patient)\n",
    "- The most critical variable is the image, which is represented by its corresponding filename and stored in JPEG. The anatom_site_general is also a critical variable that stores the label of the anatomical site of the image. Some of the labels include anterior torso, lower extremity, higher extremity and palms/soles.\n",
    "- For the images of the patients affected skin, we plan to encode these JPEG images and conduct pixel normalization in binary format during our preprocessing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "<!-- In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared.  -->\n",
    "\n",
    "Our goal is to properly classify skin lesions from images. To solve this problem, we will use a mix of techniques. First we will do data preprocessing in order to make sure our data is in a form that we can use. Then we will use an unsupervised clustering algorithm to see if we can cluster different images easily. We will likely try k-means, DBSCAN, Hierarchical clustering, and Gaussian Mixed Models. We might need to do dimensionality reduction (PCA, maybe convolution) in order for these methods to work due to the curse of dimensionality. If we find that a specific clustering algorithm works particularly well, we will likely use it. We will also need to use a CNN to finalize our predictions with the help of the insights gained from clustering. \n",
    "To test our solution we will use a cross-validation technique with a testing sample separated at the beginning on which we can test on at the very end. We will use the evaluation metrics below to measure our “success.” We will also use a benchmark model using KMeans (as it is the simplest model) for our solution to be compared against. \n",
    "Libraries that we will use will likely include but is not limited to:\n",
    "Pandas, numpy, sklearn.cluster.(KMeans, DBSCAN …), sklearn.metrics, pytorch, tensorflow, matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Since we are dealing with a classification problem, doing a metric that measures our successes and failures accurately will be best. Maximizing the True Positive Rate will be our goal (recall, TP/P). We will also likely use the Positive Predictive Value (precision, TP/PP) and the F-score (2 TP /( 2 TP + FP + FN)) as it can balance if some of the size of classes is significantly different from the other. These three metrics will make sure to guide our solution to the right direction. Using these three metrics we should be able to evaluate our model accurately and we will also be able to use these tests for our validation and test set which will tell us if our model is generalizing well or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-03-21 03:20:15.875351: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-21 03:20:15.879759: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-21 03:20:15.933641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 03:20:17.503278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#importing the commands\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "\n",
    "# to get rid of warnings during models\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*threadpoolctl.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('grayscale_img.csv.zip','r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "import zipfile \n",
    "\n",
    "with zipfile.ZipFile('archive.zip','r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are defining functions that we will be using on the data in order to reduce the size of the orinigal images so that we can reduce computational power needed. Since we are reducing the size we want to make up for it my calculating the average of the images and recreating the images using the averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a directory\n",
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        #images are in jpg format\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "# Function to calculate average pixel values\n",
    "def calculate_average_pixels(images):\n",
    "    return np.mean(images, axis=(1, 2))\n",
    "\n",
    "# Function to resize images using average pixel values\n",
    "def resize_images(images, new_size=(30, 30)):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        #built in the average pixel function within the resizing\n",
    "        resized_image = np.full((new_size[0], new_size[1], 3), calculate_average_pixels([image]))\n",
    "        resized_images.append(resized_image)\n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from dataset\n",
    "dataset_directory = os.path.join('archive','ISIC_2019_Training_Input','ISIC_2019_Training_Input')\n",
    "images = load_images(dataset_directory)\n",
    "\n",
    "# Calculate average pixel values\n",
    "average_pixels = calculate_average_pixels(images)\n",
    "\n",
    "# Resize images using average pixel values\n",
    "resized_images = resize_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to show us the comparison of the first 3 images between resized(avg) image to the original. Also will be a good indication for us to see if the avg pixel is a good basis to base the kmeans and make conclusions on or if its too drastically different to acknowledge that and consider it for our final conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the original and resized image\n",
    "for i in range(3):\n",
    "    cv2.imshow('Original', images[i])\n",
    "    cv2.imshow('Resized', resized_images[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale = pd.read_csv(os.path.join('grayscale_img.csv', 'grayscale_img.csv'), index_col = 0)\n",
    "\n",
    "grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X_gray = grayscale.drop(columns = ['label'])\n",
    "y_gray = grayscale['label']\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit_transform(X_gray, y_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = pd.read_csv(os.path.join('resized_images_color.csv', 'resized_images_color.csv'))\n",
    "\n",
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X_color = color.drop(columns = ['label'])\n",
    "y_color = color['label']\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit_transform(X_color, y_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be using the data to conduct kmeans. Note the data set we will be testing on is a grayscaled, reduced sized (originally 512x512 into 30x30), and grayscaled for computational reasons. We want to point this out as it will affect results, given we are reducing and getting rid of possible features that may be important for better predictions. We used the average of pixels before reducing the size of the images to make up for the reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv that has all the changes applied already\n",
    "df = pd.read_csv(\"grayscale_img.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_clust(df, n_clusters=8):\n",
    "    # Convert DataFrame to numpy array\n",
    "    data = df.values\n",
    "    \n",
    "    # Flatten the data\n",
    "    flattened_data = data.reshape(data.shape[0], -1)\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(flattened_data)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=2)\n",
    "    data_reduced = pca.fit_transform(data_scaled)\n",
    "    \n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(data_reduced)\n",
    "    \n",
    "    # Visualize the clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cluster in range(n_clusters):\n",
    "        plt.scatter(data_reduced[cluster_labels == cluster, 0], \n",
    "                    data_reduced[cluster_labels == cluster, 1], \n",
    "                    label=f'Cluster {cluster + 1}')\n",
    "    plt.title('Clusters Visualization')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Filter numeric columns bc some vectors contain string\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "# Call vis_clust only num values, because cant run with strings\n",
    "vis_clust(numeric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "\n",
    "Now that we have the images preprocessed, we know there should be 8 different clusters since the images contain 8 different skin conditions, but we want to see how it will cluster them using k means. Also since we are doing a unsupervised portion we will be using a elbow method to decide the number of clusers, and compare to the actual amount we know is true.\n",
    "\n",
    "The kmeans at 8 clusters does a good job at clustering. Our only concern would be the top right section between cluster 4 and 5 but that is a given due to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(df, max_clusters=10):\n",
    "    distortions = []\n",
    "    for n_clusters in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        kmeans.fit(df)\n",
    "        # Sum of squared distances to closest centroid\n",
    "        distortions.append(kmeans.inertia_)  \n",
    "\n",
    "    # Plotting the elbow method\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, max_clusters + 1), distortions, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Select only numeric columns from the DataFrame\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "numeric_data = df[numeric_columns]\n",
    "\n",
    "# Prepare data\n",
    "flattened_data = np.array([image.flatten() for image in numeric_data.values])\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(flattened_data)\n",
    "\n",
    "# Run elbow method\n",
    "elbow_method(data_scaled, max_clusters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that based off the elbow graph between 2-4 is ideal for the number of clusters for our kmeans. It makes sense that it would be less than 8 because that would be overfitting, but another reason for this can be that skin lesions may minor differences, that the kmeans overlooked. We will compare how a cluster of 3 looks with respect to cluster of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# Plot with 8 clusters\n",
    "axs[0].set_title('8 clusters')\n",
    "vis_clust(numeric_df, n_clusters=8)\n",
    "\n",
    "# Plot with 3 clusters\n",
    "axs[1].set_title('3 clusters')\n",
    "vis_clust(numeric_df, n_clusters=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our df's last column contains the truths of each image, we will now be using this column to see how accurate the kmeans is with respect to what we know is true. We will be testing this for clusters=3, and 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out all the unique strings in the last column\n",
    "unique_strings = df.iloc[:, -1].unique()\n",
    "print(unique_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#Extract truths from df last column\n",
    "true_labels = df.iloc[:, -1]\n",
    "# kmeans 3 clusters\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_3.fit(data_scaled)\n",
    "labels_3 = kmeans_3.labels_\n",
    "\n",
    "#kmeans 8 clusters\n",
    "kmeans_8 = KMeans(n_clusters=8, random_state=42)\n",
    "kmeans_8.fit(data_scaled)\n",
    "labels_8 = kmeans_8.labels_\n",
    "\n",
    "# Mapping clusters to true labels\n",
    "cluster_mapping = {\n",
    "    0: 'NV',\n",
    "    1: 'MEL',\n",
    "    2: 'BKL',\n",
    "    3: 'DF',\n",
    "    4: 'SCC',\n",
    "    5: 'BCC',\n",
    "    6: 'VASC',\n",
    "    7: 'AK'\n",
    "}\n",
    "\n",
    "# Map cluster labels to true labels for 3 clusters\n",
    "predicted_labels_3 = [cluster_mapping[label] for label in labels_3]\n",
    "\n",
    "# Map cluster labels to true labels for 8 clusters\n",
    "predicted_labels_8 = [cluster_mapping[label] for label in labels_8]\n",
    "\n",
    "# Compare the accuracy of the clustering results\n",
    "accuracy_3 = accuracy_score(true_labels, predicted_labels_3)\n",
    "accuracy_8 = accuracy_score(true_labels, predicted_labels_8)\n",
    "# Print the first few predicted labels for each clustering\n",
    "print(\"\\nPredicted Labels for 3 clusters:\")\n",
    "print(predicted_labels_3[:10])  # Print the first 10 predicted labels for 3 clusters\n",
    "print(\"\\nPredicted Labels for 8 clusters:\")\n",
    "print(predicted_labels_8[:10])  # Print the first 10 predicted labels for 8 clusters\n",
    "print(\"Accuracy with 3 clusters:\", accuracy_3)\n",
    "print(\"Accuracy with 8 clusters:\", accuracy_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to our low accuracy score in our image predicting models. We looked to the metadata of the images in an attempt to create a predictive model using those statistics of the patients and see if that is better at prediciting the skin lesion. \n",
    "\n",
    "Things to know from the following data it consists of 5 columns (image, age_approx, site, lesion id, sex). We needed to clean the data a bit specifically remove any rows without a lesion id. We then got rid of portion of the string in the lesion id, because the data included the lesion id with respect to the image. The reason for this is to be able to use this column as our ground truths for validation. Lastly we convert the sex column from string to numerical values in our case female=0, and male=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata from the CSV file\n",
    "metadata_df = pd.read_csv(\"ISIC_2019_Training_Metadata.csv\")\n",
    "\n",
    "# Drop rows where 'lesion_id' is blank or missing\n",
    "metadata_df.dropna(subset=['lesion_id'], inplace=True)\n",
    "\n",
    "# Remove characters after the underscore in 'lesion_id' column\n",
    "metadata_df['lesion_id'] = metadata_df['lesion_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Convert strings in the 'sex' column to numerical values\n",
    "metadata_df['sex'] = metadata_df['sex'].map({'female': 0, 'male': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "\n",
    "We will now be creating a hierarchical clustering dendogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "metadata_df['anatom_site_general'] = label_encoder.fit_transform(metadata_df['anatom_site_general'])\n",
    "\n",
    "# Select features for clustering\n",
    "features = metadata_df[['age_approx', 'anatom_site_general','sex']]\n",
    "# Impute NaN values with mean\n",
    "features = features.fillna(features.mean())\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(features, method='ward')\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z, truncate_mode='lastp', p=30, leaf_rotation=90., leaf_font_size=8.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adjusted the x axis, to show the range of sample index's otherwise it would not be legible given the number of samples we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "#Remove missing or blank values from metadata\n",
    "metadata_df = metadata_df.dropna(subset=['lesion_id'])\n",
    "\n",
    "#Ground Truth for validation\n",
    "ground_truth_labels = metadata_df['lesion_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "#Define a range of threshold distances\n",
    "thresholds = range(10, 500, 5)\n",
    "\n",
    "best_ari = -1\n",
    "best_t = None\n",
    "\n",
    "for t in thresholds:\n",
    "    # Obtain cluster labels\n",
    "    cluster_labels = fcluster(Z, t, criterion='distance')\n",
    "    \n",
    "    # Calculate ARI\n",
    "    ari = adjusted_rand_score(ground_truth_labels, cluster_labels)\n",
    "    \n",
    "    # Update best ARI and threshold if ARI improves\n",
    "    if ari > best_ari:\n",
    "        best_ari = ari\n",
    "        best_t = t\n",
    "\n",
    "print(\"Best threshold distance (t):\", best_t)\n",
    "print(\"Best Adjusted Rand Index (ARI):\", best_ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The for loop was used to find the best t value to get the highest ari. Unfortunately we still have a low score of  less than .1 which means our clustering did a very poor job at correctly prediciting with respect to the ground truths\n",
    "\n",
    "The following we will be doing a second Hierarchical Clustering but this time we will imnplement weights to the features to see if this will improve ARI score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have metadata features stored in 'X' and lesion types stored in 'y'\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_scaled, ground_truth_labels)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Normalize feature importances to create weights\n",
    "weights = feature_importances / feature_importances.sum()\n",
    "\n",
    "# Print feature importance weights\n",
    "print(\"Feature Importance Weights:\")\n",
    "for feature, weight in zip(metadata_df.columns, weights):\n",
    "    print(f\"{feature}: {weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Normalize metadata features using weights\n",
    "weighted_features = X_scaled * weights\n",
    "\n",
    "# Compute the weighted Euclidean distance matrix\n",
    "weighted_distance_matrix = pdist(weighted_features)\n",
    "\n",
    "# Perform hierarchical clustering with weighted distance matrix\n",
    "Z = linkage(weighted_distance_matrix, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Hierarchical Clustering Dendrogram with Weights')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z, truncate_mode='lastp', p=30, leaf_rotation=90., leaf_font_size=8.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Remove missing or blank values from metadata\n",
    "metadata_df = metadata_df.dropna(subset=['lesion_id'])\n",
    "\n",
    "# Ground Truth for validation\n",
    "ground_truth_labels = metadata_df['lesion_id'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Define a range of threshold distances\n",
    "thresholds = range(10, 500, 5)\n",
    "\n",
    "best_ari = -1\n",
    "best_t = None\n",
    "\n",
    "for t in thresholds:\n",
    "    # Obtain cluster labels with weighted hierarchical clustering\n",
    "    cluster_labels = fcluster(Z, t, criterion='distance')\n",
    "    \n",
    "    # Calculate ARI\n",
    "    ari = adjusted_rand_score(ground_truth_labels, cluster_labels)\n",
    "    \n",
    "    # Update best ARI and threshold if ARI improves\n",
    "    if ari > best_ari:\n",
    "        best_ari = ari\n",
    "        best_t = t\n",
    "\n",
    "print(\"Best threshold distance (t):\", best_t)\n",
    "print(\"Best Adjusted Rand Index (ARI):\", best_ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our ARI has increased significantly when we incorporated weights before it was roughly 0.02 and now the ARI is roughly 0.16. Meaning our model improved in predicting the ground truth, but it is still low when considering the ARI score where ARI=1 perfect prediction. With this said since it is >0 meaning it performs better than random prediction.\n",
    "\n",
    "### Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_clust_gmm(data, n_clusters=9):\n",
    "    flattened_data = np.array([image.flatten() for image in data])\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(flattened_data)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    data_reduced = pca.fit_transform(data_scaled)\n",
    "\n",
    "    #Gaussian Mixture Model\n",
    "    gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    gmm.fit(data_reduced)\n",
    "    cluster_labels = gmm.predict(data_reduced)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        plt.scatter(data_reduced[cluster_labels == cluster, 0], \n",
    "                    data_reduced[cluster_labels == cluster, 1], \n",
    "                    label=f'Cluster {cluster + 1}')\n",
    "    plt.title('GMM Clusters Visualization')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "vis_clust_gmm(resized_images, n_clusters=9) \n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def evaluate_gmm_silhouette(data, n_clusters=9):\n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(data_reduced, cluster_labels)\n",
    "    print(f'Silhouette Score for {n_clusters} clusters: {silhouette_avg:.3f}')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        plt.scatter(data_reduced[cluster_labels == cluster, 0], \n",
    "                    data_reduced[cluster_labels == cluster, 1], \n",
    "                    label=f'Cluster {cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/demo/Desktop/COGS118B_WI_24/Project/archive/ISIC_2019_Training_GroundTruth.csv\", header = 0)\n",
    "lesion_type_dict = {\n",
    "    'NV': 'Melanocytic nevi',\n",
    "    'MEL': 'Melanoma',\n",
    "    'BKL': 'Benign keratosis ',\n",
    "    'BCC': 'Basal cell carcinoma',\n",
    "    'AK': 'Actinic keratoses',\n",
    "    'VASC': 'Vascular lesions',\n",
    "    'DF': 'Dermatofibroma',\n",
    "    'SCC' : 'Squamous cell carcinoma'\n",
    "}\n",
    "data['truth'] = data.drop(columns='image').idxmax(axis=1)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    dir = Path(path)\n",
    "    filepaths = list(dir.glob(r'**/*.jpg'))\n",
    "    labels = data['truth']\n",
    "    filepaths = pd.Series(filepaths, name='FilePaths').astype(str)\n",
    "    labels = pd.Series(labels, name='Labels').astype(str)\n",
    "    df = pd.merge(filepaths, labels, right_index=True, left_index=True)\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "df = load_data('/Users/demo/Desktop/COGS118B_WI_24/Project/archive/ISIC_2019_Training_Input/ISIC_2019_Training_Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count = df['Labels'].value_counts(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(labels_count.index, labels_count.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Labels'] = df['Labels'].apply(lambda x: x if x == 'NV' else 'OTH')\n",
    "df_binary = df['Labels']\n",
    "binary = np.array([-1 if x == 'OTH' else 1 for x in df_binary])\n",
    "binary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data is heavily biased towards NV, and has low numbers of other diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('archive/ISIC_2019_Training_GroundTruth.csv')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesWithLabels = pd.DataFrame()\n",
    "filesWithLabels['file'] = files['image']+'.jpg'\n",
    "filesWithLabels['label'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesWithLabels['label'] = data['truth']\n",
    "filesWithLabels['file'] = 'archive/ISIC_2019_Training_Input/ISIC_2019_Training_Input/'+filesWithLabels['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(filesWithLabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 1\n",
    "def get_model():   \n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(128, 128, 3)),\n",
    "        Conv2D(16, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\", padding=\"same\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,  \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "def plot_history(history, title):\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_models(model,name):\n",
    "    dest_folder = '/kaggle/working/'\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    with open(dest_folder  + name +\".tflite\", 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "def create_model(table, name, epoch):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=table,\n",
    "        directory=None,\n",
    "        x_col='file',\n",
    "        y_col='label',\n",
    "        subset=\"training\",\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"binary\",\n",
    "        target_size=(128, 128))\n",
    "    val_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=table,\n",
    "        directory=None,\n",
    "        x_col='file',\n",
    "        y_col='label',\n",
    "        subset=\"validation\",\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"binary\",\n",
    "        target_size=(128, 128))\n",
    "    # Create a function that yields samples\n",
    "    model = get_model()\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(train_generator, epochs=epoch, validation_data=val_generator, callbacks=[early_stop])\n",
    "    return history, model     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVTable = pd.concat([X_train.loc[X_train['label'] != 'NV'].sample(n=8000), X_train.loc[X_train['label'] == 'NV']])\n",
    "NVTable['label'] = NVTable['label'].apply(lambda x: 'OTH' if x != 'NV' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'MEL'].shape[0]\n",
    "MELTable = pd.concat([X_train.loc[X_train['label'] != 'MEL'].sample(n=n), X_train.loc[X_train['label'] == 'MEL']])\n",
    "MELTable['label'] = MELTable['label'].apply(lambda x: 'OTH' if x != 'MEL' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'BKL'].shape[0]\n",
    "BKLTable = pd.concat([X_train.loc[X_train['label'] != 'BKL'].sample(n=n), X_train.loc[X_train['label'] == 'BKL']])\n",
    "BKLTable['label'] = BKLTable['label'].apply(lambda x: 'OTH' if x != 'BKL' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'DF'].shape[0]\n",
    "DFTable = pd.concat([X_train.loc[X_train['label'] != 'DF'].sample(n=n), X_train.loc[X_train['label'] == 'DF']])\n",
    "DFTable['label'] = DFTable['label'].apply(lambda x: 'OTH' if x != 'DF' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'SCC'].shape[0]\n",
    "SCCTable = pd.concat([X_train.loc[X_train['label'] != 'SCC'].sample(n=n), X_train.loc[X_train['label'] == 'SCC']])\n",
    "SCCTable['label'] = SCCTable['label'].apply(lambda x: 'OTH' if x != 'SCC' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'BCC'].shape[0]\n",
    "BCCTable = pd.concat([X_train.loc[X_train['label'] != 'BCC'].sample(n=n), X_train.loc[X_train['label'] == 'BCC']])\n",
    "BCCTable['label'] = BCCTable['label'].apply(lambda x: 'OTH' if x != 'BCC' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'VASC'].shape[0]\n",
    "VASCTable = pd.concat([X_train.loc[filesWithLabels['label'] != 'VASC'].sample(n=n), X_train.loc[X_train['label'] == 'VASC']])\n",
    "VASCTable['label'] = VASCTable['label'].apply(lambda x: 'OTH' if x != 'VASC' else x)\n",
    "\n",
    "n = X_train.loc[X_train['label'] == 'AK'].shape[0]\n",
    "AKTable = pd.concat([X_train.loc[X_train['label'] != 'AK'].sample(n=n), X_train.loc[X_train['label'] == 'AK']])\n",
    "AKTable['label'] = AKTable['label'].apply(lambda x: 'OTH' if x != 'AK' else x)\n",
    "\n",
    "tables = {\n",
    "    \"AK\": AKTable,\n",
    "    \"NV\": NVTable,\n",
    "    \"MEL\": MELTable,\n",
    "    \"BKL\": BKLTable,\n",
    "    \"DF\": DFTable,\n",
    "    \"SCC\": SCCTable,\n",
    "    \"BCC\": BCCTable,\n",
    "    \"VASC\": VASCTable,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVTable_test = pd.concat([X_test.loc[X_test['label'] != 'NV'].sample(n=1000), X_test.loc[X_test['label'] == 'NV']])\n",
    "NVTable_test['label'] = NVTable_test['label'].apply(lambda x: 'OTH' if x != 'NV' else x)\n",
    "\n",
    "n = X_test.loc[X_test['label'] == 'MEL'].shape[0]\n",
    "MELTable_test = pd.concat([X_test.loc[X_test['label'] != 'MEL'].sample(n=n), X_test.loc[X_test['label'] == 'MEL']])\n",
    "MELTable_test['label'] = MELTable_test['label'].apply(lambda x: 'OTH' if x != 'MEL' else x)\n",
    "\n",
    "n = X_test.loc[X_test['label'] == 'BKL'].shape[0]\n",
    "BKLTable_test = pd.concat([X_test.loc[X_test['label'] != 'BKL'].sample(n=n), X_test.loc[X_test['label'] == 'BKL']])\n",
    "BKLTable_test['label'] = BKLTable_test['label'].apply(lambda x: 'OTH' if x != 'BKL' else x)\n",
    "\n",
    "n = X_test.loc[X_test['label'] == 'DF'].shape[0]\n",
    "DFTable_test = pd.concat([X_test.loc[X_test['label'] != 'DF'].sample(n=n), X_test.loc[X_test['label'] == 'DF']])\n",
    "DFTable_test['label'] = DFTable_test['label'].apply(lambda x: 'OTH' if x != 'DF' else x)\n",
    "\n",
    "n = X_test.loc[X_test['label'] == 'SCC'].shape[0]\n",
    "SCCTable_test = pd.concat([X_test.loc[X_test['label'] != 'SCC'].sample(n=n), X_test.loc[X_test['label'] == 'SCC']])\n",
    "SCCTable_test['label'] = SCCTable_test['label'].apply(lambda x: 'OTH' if x != 'SCC' else x)\n",
    "\n",
    "n = X_test.loc[X_test['label'] == 'BCC'].shape[0]\n",
    "BCCTable_test = pd.concat([X_test.loc[X_test['label'] != 'BCC'].sample(n=n), X_test.loc[X_test['label'] == 'BCC']])\n",
    "BCCTable_test['label'] = BCCTable_test['label'].apply(lambda x: 'OTH' if x != 'BCC' else x)\n",
    "\n",
    "n = X_test.loc[X_test['label'] == 'VASC'].shape[0]\n",
    "VASCTable_test = pd.concat([X_test.loc[X_test['label'] != 'VASC'].sample(n=n), X_test.loc[X_test['label'] == 'VASC']])\n",
    "VASCTable_test['label'] = VASCTable_test['label'].apply(lambda x: 'OTH' if x != 'VASC' else x)\n",
    "\n",
    "n = X_test.loc[X_test['label'] == 'AK'].shape[0]\n",
    "AKTable_test = pd.concat([X_test.loc[X_test['label'] != 'AK'].sample(n=n), X_test.loc[X_test['label'] == 'AK']])\n",
    "AKTable_test['label'] = AKTable_test['label'].apply(lambda x: 'OTH' if x != 'AK' else x)\n",
    "\n",
    "tables = {\n",
    "    \"AK\": AKTable_test,\n",
    "    \"NV\": NVTable_test,\n",
    "    \"MEL\": MELTable_test,\n",
    "    \"BKL\": BKLTable_test,\n",
    "    \"DF\": DFTable_test,\n",
    "    \"SCC\": SCCTable_test,\n",
    "    \"BCC\": BCCTable_test,\n",
    "    \"VASC\": VASCTable_test,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tables.keys():\n",
    "    hist_1, mdl_1 = create_model(tables[i], str(i) + \" model, validation\", 7)\n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=tables_test[i], \n",
    "        directory=None, \n",
    "        x_col='file', \n",
    "        y_col='label',\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=False, \n",
    "        class_mode=\"binary\",\n",
    "        target_size=(128, 128)\n",
    "        )\n",
    "    eval_result = mdl_1.evaluate(test_generator)\n",
    "    print(f\"Test Loss: {eval_result[0]}, Test Accuracy: {eval_result[1]}\")\n",
    "    plot_history(hist_1, str(i) + \" model, validation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AK_VAL](images/AK_VAL.png)"
   ]
  }
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results / Discussion\n",
    "\n",
    "### PCA and LDA\n",
    "Our first intuition was to run PCA on our data and see which principle vectors were best and try to split our data that way. After trying different principle vectors, we realized that PCA was measuring a lot of the noise in our data. This was especially true on the 30x30x1 data, where most of the features were noise as the details that we were measuring were squished. \n",
    "We then ran LDA to try to find another way to split the data into clusters. We believe that LDA could be successful in splitting the data as in theory it would be better than PCA, but in practicality with version of the data it was not successful for the same reasons that PCA and a lot of the following algorithms were not successful.\n",
    "Finding a way to do dimensional reduction was essential for the clustering algorithm to work, which we were not successful in doing so. This means that the following sections are limited in usability because of this and the issues discussed in limitations.\n",
    "### UMAP and t-SNE\n",
    "To try to see if reducing the data could lead to some local structure on which we could run a clustering algorithm, we ran both t-SNE and UMAP. We ran t-SNE for 5 different perplexities and UMAP for 20 different neighbors and minimum distance. Unfortunately neither t-SNE or UMAP led to a separation of our data in a way that was meaningful. This is likely due to the fact that most of the data is noice (the skin) and the difference that we are trying to measure is just a small feature of the images. Hence our metrics on these algorithms are not great as the data was not able to be separated. \n",
    "DB-Scan\n",
    "With DB-Scan we ran into a lot of the same issues as with UMAP and t-SNE. We couldn’t separate our data well into different clusters, so running DB-Scan did not lead to great results. \n",
    "\n",
    "\n",
    "### Gaussian Mixture Model\n",
    "Our investigation in classifying skin lesions based on imaging data led us to the Gaussian Mixture Model clustering approach. The aim was to explore the underlying patterns in the data. The data was preprocessed, standardized, and dimensionally reduced using PCA which simplified the data for visualization. We applied GMM with nine clusters corresponding with the nine skin lesion types. After fitting the model to the dimensionally reduced data, each image was assigned to a cluster, with the aim of grouping similar lesion types together. The clustering results were visualized in the reduced two dimensional space. The visualization revealed more defined clusters, however this contrasted with the distribution of true labels which appeared more scattered and less cohesive. This shows that the patterns within the data do not align well with predefined lesion types. SO the Gaussian Mixture model is not the best clustering algorithm for this project. \n",
    "\n",
    "\n",
    "### Neural Network Results\n",
    "For the classification Neural Network, we first tried to do a multi class classifier. Creating multiple neural networks to try different convolution and options of learnable parameters, the accuracy we would get would be around 52%, which is not bad for 8 possible classes but still not great. To try to improve the model. We decided to train multiple binary classifiers. To do so we added some image transformations for the model to generalize better and created random datasets which encompass an equal number of positive and negative classes. After running 3 epochs, our models had the following accuracies:\n",
    "AK: 0.75\n",
    "NV: 0.80 \n",
    "MEL: 0.74\n",
    "BKL: 0.54\n",
    "DF: 0.68\n",
    "SCC:0.73\n",
    "BCC: 0.80\n",
    "VASC: 0.74\n",
    "The following scores show a great improvement from the previous multi-class model. Some of the limitations we had were computing power as due to the nature of the large dataset and the loading of the images, we could only load a smaller image size. At first we worked with 30x30x3 images (30 pixels by 30, 3 channels for red, blue and green). The second model we managed to upscale the images to 128x128x3, but even then the quality is low for human eyes and differentiating and being able to point out details that make specific lesions is very hard. If we had a better computing machine, we would have run it on 512x512x3 as that is a size that is a lot easier to see the difference between lesions. Having more computing power would also let us run more epochs which could lead to a higher chance of finding a better way to classify the classes. Overall there are still a lot of things that can be done to improve this neural network, but given the time it takes to run each model (around 8 hours) and the time limitations of this project, this is the best that we have come up with in the given time frame. \n",
    "\n",
    "\n",
    "### Limitations\n",
    "\n",
    "There are a lot of possible improvements to be made to this model. The first is having a stronger computer that can handle the high dimensionality of our data and the big size of the dataset. We had issues with uploading the data on datahub or collab, which meant that most of the code was run locally. Even then, we all dealt with dead kernels and our laptops crashing running this code. This made making progress extremely tough. When running code did work, we had computation limitations. We were only able to use 30x30x1 data for most of our project which meant the feature that we were looking for tended to be lost. For the neural network we managed to load the way in a more efficient way in the neural network which was able to work on 128x128x3 data. This led to more promising results, and we believe that if we were able to work with 512x512x3 data that we would be able to have a lot higher accuracy. This is also true of our clustering algorithm, with more details we would be able to find the vector on which the clusters are best split by, (which again the details are lost in 30x30x1 data).    \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "In terms of ethical concerns the main issue is where the images are sourced from, and whether or not the people in the photos have given their consent for researchers to study them. In our case photos do not contain any faces, they are high resolution photos of the skin disease site only. It seems some sort of microscope was used to take these pictures. The data was obtained from a hospital in Barcelona, where the patient's consent was given. We sourced the dataset from Kaggle which is a reliable source for ethical data. Another ethical concern is what this data will be used for. In our case the model we create will only benefit humanity, because people can detect skin melanoma or other cancerous diseases in early stages and seek medical care as soon as possible.\n",
    "\n",
    " We want to emphasize, that our models should not be a main source of diagnosing patients or people that have concerns with regarding to their skin lesions. Since our model did not perform great as we have anticipated it is not a reliable diagnosing tool. Had it performed better we would still advise the general public to seek professional and experienced medical doctors to diagnose their skin lesions.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Our clustering methods did not work since we were unable to separate the data and therefore did not perform well when it comes to clustering skin lesions. On the other hand, The  Neural Network performed relatively well with some skin lesions having a 80 % accuracy. Relating to the article in which the general public could not trust some medical experts to correctly diagnose them, our methods and models  can use some improvements before they can be exposed to the public. For future work we would encourage it first to rerun the models using the original dataset images. We then encourage them to adjust the images to zoom into the skin lesion and remove the hair if possible to reduce noise for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "1.^: Hafner K. and Palmer G. (20 Nov 2017) Skin Cancers Rise, Along With Questionable Treatments. The New York Times https://www.nytimes.com/2017/11/20/health/dermatology-skin-cancer.html\n",
    "\n",
    "2.^: Skuhala, Tomislava, et al. “Analysis of Types of Skin Lesions and Diseases in Everyday Infectious Disease Practice- How Experienced Are We?” Life, vol. 12, no. 7, 29 June 2022, p. 978, Https://doi.org/10.3390/life12070978 .  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9319552/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
